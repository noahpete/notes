\lecture{18}{16 Mar. 12:00}{Cache Organization: Block Size and Writes}

\begin{definition}[k-Way Set Associative LRU]
  A set associative LRU with \emph{k} \textbf{ways}, has essentially \emph{k} cells within each cache line's block. The LRU is set to be the \emph{way} with the highest \emph{count}. 20:43
\end{definition}

Each cache hit now essentially brings in two blocks of data, since each block in memory is paired up with an adjacent block. Now, we can have the LSB of our memory address correspond to either block A or block B of the retrieved block, and the remaining bits correspond to a (now-shortened) memory address.

\begin{definition}[Spatial Locality]
  \textbf{Spatial locality} in a program says that we reference a memory location (e.g., 1000), we are more likely to reference a location near it (e.g., 1001) than some random location.
\end{definition}

\section{Cache Organization}
We now consider the design of a cache.

\subsection{Block Size}
\begin{itemize}
  \item choice of block size found by simiulating lots of different block sizes and seeing which ones give the best performance
  \item most systems use a block size between 32 and 128 bytes
  \item \emph{longer sizes} reduce overhead by reducing the number of CAM entries and reducing the size of each CAM entry
\end{itemize}

\begin{problem}
  Given a cache with the following configuration:
  \begin{itemize}
    \item total size is 8 bytes
    \item block size is 2 bytes
    \item fully associative
    \item LRU replacement
    \item memory address size is 16bits and is byte addressable
  \end{itemize}
  \begin{enumerate}
    \item How many bits are for each tag? How many blocks in the cache?
    \item For the following reference stream, indicate whether each reference is a hit or miss: 0, 1, 3, 5, 12, 1, 2, 9, 4.
  \end{enumerate}
\end{problem}
\begin{answer}
  \begin{enumerate}
    \item 
  \end{enumerate}
\end{answer}